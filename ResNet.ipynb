{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解压文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tar = tarfile.open('/content/CUB_200_2011.tgz')     \n",
    "tar.extractall('/content')                      # 解压文件到/content目录下\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据并划分训练集、测试集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size):\n",
    "  \"\"\"\n",
    "  将图像重构成224*224的像素\n",
    "  shuffle=True时，数据加载器会在每个时期重新洗牌数据，以增加训练的随机性。这对于避免模型过度拟合训练数据、增加模型的泛化能力非常重要。\n",
    "  DataLoader类创建训练集、验证集和测试集的数据加载器。数据加载器用于批量加载数据，并提供数据的迭代器。\n",
    "  将同一类的图像放在一个文件夹中，此函数会自动分辨哪个图像属于哪一类.\n",
    "  接受两个参数：data_dir（数据集所在的目录）和batch_size（批量大小）\n",
    "  \"\"\"\n",
    "  transform = transforms.Compose([transforms.Resize(256),\n",
    "                   transforms.CenterCrop(224),\n",
    "                   transforms.ToTensor()])\n",
    "  all_data = datasets.ImageFolder(data_dir, transform=transform)\n",
    "  train_data_len = int(len(all_data)*0.75)\n",
    "  valid_data_len = int((len(all_data) - train_data_len)/2)\n",
    "  test_data_len = int(len(all_data) - train_data_len - valid_data_len)\n",
    "  train_data, val_data, test_data = random_split(all_data, [train_data_len, valid_data_len, test_data_len])\n",
    "  train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "  val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "  test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "  #使用\n",
    "  #\n",
    "  return ((train_loader, val_loader, test_loader),train_data, val_data, test_data, all_data.classes)\n",
    "\n",
    "(train_loader, val_loader, test_loader),train_data, val_data, test_data, classes = get_data_loaders(\"images_path/\", 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将图像进行归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\" \n",
    "    通过调用 clamp_ 方法，将图像张量中的值约束在 image_min 和 image_max 之间\n",
    "    调用 add_ 方法将 image_min 从图像张量中减去，使得最小值变为 0\n",
    "    调用 div_ 方法将图像张量除以 image_max - image_min + 1e-5，进行归一化操作\n",
    "    最后，返回归一化后的图像张量\n",
    "\n",
    "    \"\"\"\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示图像和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_images(images, labels, normalize = True):\n",
    "    \"\"\" \n",
    "    plot_images 的函数，用于绘制图像和对应的标签\n",
    "    引用了 normalize_image 函数，因此在调用 plot_images 函数之前，需要确保已经定义了 normalize_image 函数。\n",
    "\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        image = images[i]\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = labels[i]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "N_IMAGES = 25    #从训练数据中选择前 N_IMAGES 个样本，并将它们的图像和标签传递给 plot_images 函数进行绘制\n",
    "images, labels = zip(*[(image, label) for image, label in\n",
    "                           [train_data[i] for i in range(N_IMAGES)]])\n",
    "plot_images(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "\n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "\n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "\n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "\n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "\n",
    "        return x, h\n",
    "    \n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,\n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1,\n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        i = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])\n",
    "#ResNetConfig是一个命名元组，通过namedtuple函数创建。\n",
    "#它有三个字段：'block'、'n_blocks'和'channels'。这些字段分别表示块类、每个层中的块数量和每个层中的通道数。\n",
    "#通过使用这个命名元组，我们可以更方便地定义和传递ResNet模型的配置信息\n",
    "\n",
    "\n",
    "resnet18_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [2,2,2,2],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet34_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [3,4,6,3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1,\n",
    "                               stride = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
    "                               stride = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1,\n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        i = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resnet50_config = ResNetConfig(block = Bottleneck,\n",
    "                               n_blocks = [3, 4, 6, 3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet101_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 4, 23, 3],\n",
    "                                channels = [64, 128, 256, 512])\n",
    "\n",
    "resnet152_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 8, 36, 3],\n",
    "                                channels = [64, 128, 256, 512])\n",
    "\n",
    "\n",
    "\n",
    "class CIFARResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        block, layers, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "\n",
    "        assert len(layers) == len(channels) == 3\n",
    "        assert all([i == j*2 for i, j in zip(channels[1:], channels[:-1])])\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.layer1 = self.get_resnet_layer(block, layers[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, layers[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, layers[2], channels[2], stride = 2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "\n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        if self.in_channels != channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "\n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "\n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(channels, channels))\n",
    "\n",
    "        self.in_channels = channels\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "\n",
    "        return x, h\n",
    "    \n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, f):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "class CIFARBasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,\n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,\n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        if downsample:\n",
    "            identity_fn = lambda x : F.pad(x[:, :, ::2, ::2],\n",
    "                                           [0, 0, 0, 0, in_channels // 2, in_channels // 2])\n",
    "            downsample = Identity(identity_fn)\n",
    "        else:\n",
    "            downsample = None\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        i = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "cifar_resnet20_config = ResNetConfig(block = CIFARBasicBlock,\n",
    "                                     n_blocks = [3, 3, 3],\n",
    "                                     channels = [16, 32, 64])\n",
    "\n",
    "cifar_resnet32_config = ResNetConfig(block = CIFARBasicBlock,\n",
    "                                     n_blocks = [5, 5, 5],\n",
    "                                     channels = [16, 32, 64])\n",
    "\n",
    "cifar_resnet44_config = ResNetConfig(block = CIFARBasicBlock,\n",
    "                                     n_blocks = [7, 7, 7],\n",
    "                                     channels = [16, 32, 64])\n",
    "\n",
    "cifar_resnet56_config = ResNetConfig(block = CIFARBasicBlock,\n",
    "                                     n_blocks = [9, 9, 9],\n",
    "                                     channels = [16, 32, 64])\n",
    "\n",
    "cifar_resnet110_config = ResNetConfig(block = CIFARBasicBlock,\n",
    "                                      n_blocks = [18, 18, 18],\n",
    "                                      channels = [16, 32, 64])\n",
    "\n",
    "cifar_resnet1202_config = ResNetConfig(block = CIFARBasicBlock,\n",
    "                                       n_blocks = [20, 20, 20],\n",
    "                                       channels = [16, 32, 64])\n",
    "\n",
    "\n",
    "\n",
    "pretrained_model = models.resnet50(pretrained = True)\n",
    "#使用torchvision库中的resnet50函数加载预训练的ResNet-50模型。\n",
    "#设置pretrained=True将自动下载并加载预训练的权重参数。\n",
    "#现在，pretrained_model将包含加载的预训练ResNet-50模型。\n",
    "\n",
    "\n",
    "\n",
    "IN_FEATURES = pretrained_model.fc.in_features\n",
    "#IN_FEATURES获取了预训练模型的最后一个线性层(fc)的输入特征维度，即2048。\n",
    "\n",
    "\n",
    "OUTPUT_DIM = 200\n",
    "#然后，OUTPUT_DIM被设置为200，以适应您的数据集中的类别数。\n",
    "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "#最后，使用nn.Linear创建了一个新的线性层fc，其输入特征维度为IN_FEATURES，输出特征维度为OUTPUT_DIM。\n",
    "#这个新的线性层将用作预训练模型的最后一层，以适应您的数据集。\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
